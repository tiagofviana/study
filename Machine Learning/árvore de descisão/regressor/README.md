# √Årvore de decis√£o de regress√£o

- [1. Crit√©rios de divis√£o](#1-crit√©rios-de-divis√£o)
- [2. Melhorias e varia√ß√µes](#2-melhorias-e-varia√ß√µes)
- [3. Algoritmos](#3-algoritmos)

## 1. Crit√©rios de divis√£o

### 1.2 Impureza

> **DEFINI√á√ÉO:** √â uma medida de impureza ou desigualdade de um n√≥. Ela varia entre 0 e 1, onde 0 indica que todos os elementos em um n√≥ pertencem ao mesmo grupo (homog√™neo), e 1 indica uma divis√£o uniforme entre as classes. A impureza √© medida com base na variabilidade dos valores cont√≠nuos na vari√°vel dependente.


#### 1.2.1 Soma dos Quadrados dos Erros (SSE)

> **DEFINI√á√ÉO:** m√©trica utilizada para medir a diferen√ßa entre os valores reais e os valores preditos em um modelo de regress√£o


Formula:
```math
    SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
```
- _yi_ √© o valor real da amostra (observado).
- _y^i_ √© o valor predito pelo modelo para a amostra _i_.
- _n_ √© o n√∫mero total de amostras ou dados no conjunto.

> **Detalhe**: O **res√≠duo** √© a diferen√ßa entre o valor real observado (ou valor verdadeiro) e o valor predito pela √°rvore para uma dada observa√ß√£o, ou seja:

```math
    \text{Res√≠duo}_i = y_i - \hat{y}_i
```

#### 1.2.1.1 Interpreta√ß√£o:
- **SSE menor**: Quanto menor o valor do SSE, melhor o modelo, pois significa que as previs√µes do modelo est√£o mais pr√≥ximas dos valores reais.

- **SSE maior**: Um valor maior indica que o modelo tem um erro maior nas previs√µes e n√£o est√° ajustando bem os dados.


#### 1.2.3 R-quadrado

> **DEFINI√á√ÉO:** m√©trica que avalia o desempenho de modelos de regress√£o.

Formula:
```math
   R^2 = 1 - \frac{SSE}{SST}
```

- _SSE_ √© a soma dos quadrados dos erros, ou seja, a diferen√ßa entre os valores reais e as previs√µes do modelo. 
- _SST_ √© a soma total dos quadrados, ou seja, a diferen√ßa entre os valores reais e a m√©dia dos valores reais.

##### 1.2.5.1 Interpreta√ß√£o

- **ùëÖ2 < 0**: Em alguns casos (quando o modelo √© muito ruim), o R quadrado pode ser negativo, indicando que o modelo est√° ajustando os dados pior do que uma simples m√©dia. Isso pode ocorrer em modelos mal ajustados ou se voc√™ for for√ßar o modelo a se ajustar a dados que claramente n√£o s√£o lineares.
- **R2 = 0**: o modelo n√£o consegue explicar nenhuma variabilidade dos dados. O modelo est√° basicamente fazendo previs√µes aleat√≥rias.
- **ùëÖ2 = 1**: o modelo consegue explicar toda a variabilidade dos dados. As previs√µes do modelo s√£o perfeitas, ou seja, os valores preditos coincidem com os reais.
- **0 < ùëÖ2 < 1**: o modelo explica uma certa porcentagem da variabilidade dos dados. Quanto mais pr√≥ximo de 1, melhor o modelo se ajusta aos dados.

### 2. Melhorias e varia√ß√µes

- **Random Forests**: Conjunto de √°rvores de decis√£o que reduz a variabilidade, treinando v√°rias √°rvores com amostras e subconjuntos de caracter√≠sticas aleat√≥rias.
- **Boosting**: T√©cnica que combina v√°rias √°rvores fracas, treinadas de forma sequencial, onde cada √°rvore corrige os erros da anterior.

#### 2.1 Tratar um overfiting
Alguns dos principais hiperpar√¢metros que podem ser ajustados para controlar a complexidade da √°rvore e reduzir o overfitting:

1. Profundidade M√°xima da √Årvore (max_depth)
2. N√∫mero M√≠nimo de Amostras por N√≥ (min_samples_split)
3. N√∫mero M√≠nimo de Amostras por Folha (min_samples_leaf)
4. Valor M√°ximo de Caracter√≠sticas (max_features)
5. Poda (Pruning)


## 3. Algoritmos

Ser√° utilziado o python. Segue abaixo o comando das para instalar as ferramentas utilizadas:

```sh
    pip install pandas seaborn matplotlib scikit-learn
```

C√≥digo: [./main.py](./main.py)