# Redes neurais

- [1. Introdu√ß√£o](#1-introdu√ß√£o)
- [2. Estrutura](#2-estrutura)
- [3. Como as redes neurais aprendem](#3-como-as-redes-neurais-aprendem)
- [4. Tipos](#4-tipos)
- [5. Vantagens e desvantagens](#3-vantagens-e-desvantagens)
- [6. Ganho de performance](#6-ganho-de-performance)

## 1. Introdu√ß√£o

> **DEFINI√á√ÉO:** √© um modelo inspirado no funcionamento do c√©rebro humano.

Elas s√£o compostas por unidades chamadas neur√¥nios ou n√≥s, que est√£o organizados em camadas. Cada neur√¥nio recebe um conjunto de entradas, realiza um c√°lculo e gera uma sa√≠da.

Podem ser aplicadas em problemas complexos, como reconhecimento de imagem, processamento de linguagem natural, e jogos.

## 2. Estrutura

- Cada neur√¥nimo √© chamado de preceptron
- As **camadas de entrada (input layers)** recebem os dados brutos (entradas) que a rede ir√° processar. Cada neur√¥nio nesta camada corresponde a uma caracter√≠stica ou atributo do dado.
- As **camadas ocultas (hidden layers)** s√£o as camadas entre a entrada e a sa√≠da. Aqui, os neur√¥nios processam as entradas e transmitem informa√ß√µes para a pr√≥xima camada. O n√∫mero de camadas e neur√¥nios em cada camada pode variar, o que influencia a complexidade da rede.
- A **camada de sa√≠da (output layer)** gera a previs√£o ou o resultado da rede. Dependendo do tipo de problema, o n√∫mero de neur√¥nios nesta camada varia. Por exemplo, para um problema de classifica√ß√£o bin√°ria, haver√° um √∫nico neur√¥nio de sa√≠da, enquanto para uma classifica√ß√£o multiclasse, pode haver um neur√¥nio para cada classe.

### 2.1 Normaliza√ß√£o dos dados iniciais

Antes de utilzarmos os dados √©  recomendado realizar a normaliza√ß√£o ou padroniza√ß√£o para melhorar a performance do modelo.
Assim existem diferentes tipos de normaliza√ß√£o.

#### 2.1.1 Tipos

1. Mix max normalization
    - normalziar os dados entre 0 e 1 (mix max normalization). Assim, garente uma descida do gradiente descendente mais suave, diminuindo a o erro da busca e, consequentemente, o processamento.

2. StandardScaler
    - do"sklearn.preprocessing import StandardScaler" do python.
    - utilizada quando voc√™ est√° lidando com dados num√©ricos, pode haver diferentes escalas entre as vari√°veis. Por exemplo, uma vari√°vel pode estar na faixa de 0 a 1, enquanto outra pode variar entre 0 e 1000.
    - padroniza os dados para que cada caracter√≠stica tenha m√©dia 0 e desvio padr√£o 1

### 2.2 Fun√ß√£o de ativa√ß√£o

> **DEFINI√á√ÉO:** componente que determina se um neur√¥nio deve ser ativado ou n√£o, ou seja, se a informa√ß√£o recebida por esse neur√¥nio ser√° transmitida para a pr√≥xima camada.

Ela introduz n√£o linearidade no modelo, permitindo que redes neurais aprendam e representem padr√µes complexos, como os encontrados em imagens, texto ou s√©ries temporais.

Sem fun√ß√µes de ativa√ß√£o, as redes neurais seriam apenas combina√ß√µes lineares de entradas, incapazes de resolver problemas complexos. Por isso, a fun√ß√£o de ativa√ß√£o √© crucial para que as redes neurais possam aprender tarefas como reconhecimento de imagem, tradu√ß√£o de linguagem ou an√°lise de sentimentos.

#### 2.2.1 Tipos

1. **Sigmoid** (fun√ß√£o log√≠stica)
    - F√≥rmula: 
    ```math
        \sigma(z) = \frac{e^{-z}}{1 + e^{-z}}
    ```
    - Sa√≠da: Entre 0 e 1.
    - Caracter√≠sticas:
        - A fun√ß√£o comprime a sa√≠da para um intervalo de 0 a 1, o que pode ser interpretado como uma probabilidade.
    - **Desvantagem**: O problema do desvanecimento do gradiente (vanishing gradient), onde a derivada se aproxima de 0 para valores muito altos ou muito baixos de entrada, o que pode dificultar o treinamento de redes mais profundas.
    - **Aplica√ß√£o**: √â utlizadoe m tarefas onde a sa√≠da precisa ser uma probabilidade ou em problemas de classifica√ß√£o bin√°ria.

2. **Tanh** (tangente hiperb√≥lica)
    - F√≥rmula: 
    ```math
        \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
    ```
    - Sa√≠da: Entre -1 e 1.
    - Caracter√≠sticas:
        - A tangente hiperb√≥lica √© semelhante √† sigmoid, mas a sa√≠da √© centrada em torno de zero, o que pode ajudar a melhorar o desempenho durante o treinamento.
        - Pode ser √∫til em redes neurais com entradas que podem assumir valores positivos e negativos.
    - **Desvantagem**: Assim como a sigmoid, a tanh tamb√©m sofre de desvanecimento do gradiente, o que pode dificultar o treinamento de redes muito profundas.

3. **ReLU** (rectified linear unit)
    - F√≥rmula: 
    ```math
        \text{ReLU}(z) = \max(0, z)
    ```
    - Sa√≠da: Pode ser qualquer valor real, dependendo do par√¢metro ùõº
    - Caracter√≠sticas:
        - Tenta resolver o problema do neur√¥nio morto permitindo que, para entradas negativas, a fun√ß√£o tenha uma pequena inclina√ß√£o.
    - **Desvantagem**: O valor de ùõº precisa ser ajustado corretamente, o que pode tornar o treinamento um pouco mais complexo.
    - **Aplica√ß√£o**: problemas de classifica√ß√£o como, por exemplo se o cara vai pagar a d√≠vida ou n√£o.
    
4. **Linear**
    - F√≥rmula:
     ```math
        f(z) = z
    ```
    - Sa√≠da: multiplica o valor _Z_ por 1, ou seja, ele mesmo
    - Caracter√≠sticas:
        - Todas as fun√ß√µes de ativa√ß√£o entre as camadas s√£o lineares, ou seja, cada neur√¥nio realiza uma simples multiplica√ß√£o e soma dos inputs.

    - **Desvantagem**: N√£o consegue aprender padr√µes complexos, pois, apesar de ter v√°rias camadas, as sa√≠das de cada camada ainda podem ser representadas como uma combina√ß√£o linear das entradas. O que significa que, independentemente de quantas camadas voc√™ tenha, a rede ser√° equivalente a uma √∫nica camada linear. Portanto, ela tem a mesma capacidade que uma regress√£o linear.
    - **Aplica√ß√£o**: utilizadas principalmente em problemas de regress√£o, onde o objetivo √© prever uma sa√≠da cont√≠nua com base em entradas lineares.
    
### 2.3 Fun√ß√£o do erro / fun√ß√£o de custo / fun√ß√£o de perda
> **DEFINI√á√ÉO:** permite veficiar o qu√£o assertivo √© determinada previs√£o. 

S√£o diferentes para vari√°veis cont√≠nuas, discreta (√© tipos a cont√≠nua, mas possui valores finitos) e categ√≥ricas.

#### 2.3.1 Cont√≠nua e discreta

M√©tricas utilizadas para avaliar a performance de modelos de regress√£o e redes neurais.

- Erro quadr√°tico m√©dio

```math
    MSE = \frac{1}{n} \sum_{i=1}^{n} (actual - predicted)^2
```
-  Erro absoluto m√©dio
```math
    MAE = \frac{1}{n} \sum_{i=1}^{n} \left| actual - predicted \right|
```

#### 2.3.1 Categorica

- Binary cross-entropy
- Categorical cross-entropy


### 2.4 Regulariza√ß√£o

> **DEFINI√á√ÉO:** t√©cnica usada para evitar o overfitting. Em resumo, a regulariza√ß√£o adiciona uma penalidade √† fun√ß√£o de perda do modelo para evitar que os pesos da rede neural se tornem muito grandes, o que pode levar ao overfitting.

#### 2.4.1 Tipos

1. **Dropout**
    - t√©cnica que desativa aleatoriamente uma porcentagem das unidades (neur√¥nios) durante o treinamento de cada itera√ß√£o **de forma aleat√≥ria**. Isso for√ßa a rede a n√£o depender excessivamente de nenhuma unidade espec√≠fica, promovendo uma maior generaliza√ß√£o.
    - introduz "ru√≠do"

2. **L1**
    - adiciona uma penaliza√ß√£o ao **valor absoluto dos pesos**. O efeito da regulariza√ß√£o L1 √© agressivo na redu√ß√£o dos pesos para zero, o que pode levar √† sparsidade do modelo (ou seja, muitos pesos se tornam exatamente zero, o que pode ajudar na sele√ß√£o de caracter√≠sticas).

3. **L2**
    - adiciona uma penaliza√ß√£o ao **quadrado dos pesos**. Ela √° parecida com a L1, a diferen√ßa √© que ela pode levar para **pr√≥ximo** de zero.

4. **Early Stopping**
    - t√©cnica onde o treinamento da rede √© interrompido quando a performance no conjunto de valida√ß√£o come√ßa a piorar, mesmo que o erro no conjunto de treinamento continue diminuindo. Isso indica que a rede come√ßou a se ajustar excessivamente aos dados de treinamento (overfitting), e interromper o treinamento mais cedo ajuda a evitar isso.

## 3. Como as redes neurais aprendem

O aprendizado em uma rede neural √© realizado por meio de um processo chamado retropropaga√ß√£o (backpropagation). Esse processo envolve os seguintes passos:

1. **Forward pass (passagem direta)**: √© o processo no qual os dados de entrada s√£o passados atrav√©s da rede, camada por camada, at√© que a sa√≠da final seja gerada.

2. **C√°lculo do erro**: O erro √© calculado comparando a previs√£o gerada pela rede com o valor real (r√≥tulo). O erro pode ser medido usando uma fun√ß√£o de perda (por exemplo, erro quadr√°tico m√©dio ou entropia cruzada).

3. **Backward pass (retropropaga√ß√£o)**: A rede ajusta seus pesos e vieses para reduzir o erro. Isso √© feito usando o algoritmo de **gradiente descendente**, que calcula as derivadas da fun√ß√£o de perda em rela√ß√£o aos pesos e faz ajustes nos pesos para minimizar o erro.

4. **Itera√ß√£o**: Esse processo √© repetido muitas vezes (em v√°rias √©pocas), com a rede aprendendo aos poucos como fazer previs√µes mais precisas.

## 4. Tipos

### 4.1 Rede Neural Rasa (SNN - Shallow Neural Network)

Possui uma estrutura simples, com uma camada de entrada, uma √∫nica camada oculta (ou nenhuma) e uma camada de sa√≠da. 
O termo "shallow" (rasa) √© usado para contrastar com redes neurais "deep" (profundas), que possuem v√°rias camadas ocultas, ou seja, **deep learning**.

### 4.2 Redes Neurais feedforward (FNN - Feedforward Neural Network)

√â um tipo em que os neur√¥nios da mesma camada n√£o se conectam, mas cada um deles se coenctam com cada neur√¥nio da pr√≥xima camada. O termo "feedforward" se refere ao fato de que as informa√ß√µes s√£o passadas de um neur√¥nio para outro, de forma direta e unidirecional, sem retroalimenta√ß√£o.

Tamb√©m conhecida como perceptron multicamadas (MLP - Multi-Layer Perceptron)

A ordem das features n√£o √© relevante.

### 4.3 Redes Neurais Recorrentes (RNN - Recurrent Neural Networks)

Projetadas para lidar com dados sequenciais, como s√©ries temporais ou texto. Elas t√™m conex√µes "recorrentes" que permitem que informa√ß√µes anteriores influenciem o processamento atual.

A ordem das features √© relevante. Exemplo:
- O rato correu do gato.
- O gato correu do rato.
Se cada palavra √© um token, a ordem de processamento tem interferencia no resultado, a rede memoriza.
 
### 4.4 Redes Neurais Convolucionais (CNN - Convolutional Neural Networks)

Usadas principalmente em processamento de imagens e v√≠deo. Elas aplicam convolu√ß√µes para extrair caracter√≠sticas locais de uma imagem (como bordas, texturas) e s√£o muito boas para reconhecimento visual.

### 4.5 Redes Generativas (GANs - Generative Adversarial Networks):

Compostas por duas redes neurais que competem entre si: uma geradora, que cria amostras de dados, e uma discriminadora, que tenta distinguir entre dados reais e gerados. GANs s√£o usadas em tarefas como gera√ß√£o de imagens realistas e deepfakes.

## 5. Vantagens e desvantagens

Vantagens das redes neurais:
Capacidade de aprender representa√ß√µes complexas: Elas s√£o √≥timas em aprender padr√µes em grandes volumes de dados, principalmente quando esses dados s√£o altamente n√£o lineares ou complexos.
Versatilidade: Podem ser aplicadas a uma grande variedade de problemas, desde imagem at√© texto, √°udio, e muito mais.
Adaptabilidade: Elas podem melhorar com o tempo √† medida que recebem mais dados e podem aprender caracter√≠sticas que n√£o s√£o explicitamente programadas.
Desvantagens:
Necessidade de grandes quantidades de dados: Para obter bons resultados, redes neurais geralmente precisam de grandes volumes de dados para treinamento.
Consumo computacional: O treinamento de redes neurais, especialmente redes profundas, pode ser muito intensivo em termos de tempo e recursos computacionais.
Dificuldade de interpreta√ß√£o: As redes neurais s√£o frequentemente chamadas de "caixas-pretas", j√° que seus processos internos podem ser dif√≠ceis de interpretar e entender.


## 6. Ganho de performance

### 6.1 Bath

> **DEFINI√á√ÉO:** usando quando se tem restri√ß√£o de mem√≥ria, no qual os dados s√£o agrupados em "lotes". Assim, a cada intera√ß√£o, a rede processa cada um do lotes.

